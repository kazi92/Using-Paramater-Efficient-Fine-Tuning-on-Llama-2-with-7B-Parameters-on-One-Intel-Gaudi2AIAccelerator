# Using-Paramater-Efficient-Fine-Tuning-on-Llama-2-with-7B-Parameters-on-One-Intel-Gaudi2AIAccelerator
This example will Fine Tune the Llama2-7B model using Parameter Efficient Fine Tuning (PEFT) and then run inference on a text prompt.  This will be using the Llama2 model with two task examples from the Optimum Habana library on the Hugging Face model repository.
